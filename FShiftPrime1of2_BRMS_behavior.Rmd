---
title: "BRMS analysis | Posnalpha Behave | cue window"
author: "Christopher Gundlach"
date: '`r Sys.Date()`'
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    toc_depth: 4
    theme: flatly
---

# Get everything up and running

## Initialize environment
**Setting up R libraries**

```{r set up libraries,echo=FALSE,warning=FALSE,message=FALSE,results="hide"}
# Setup the work environment
options(width=120,scipen=0,digits=8) # change output width (for better printing), scientific notation (to disable it: scipen=999), constrain output to 3 decimals
cat("\014") # clear console
# dev.off() # clear plots (if no plots are present, comment it out or it will throw an error)
rm(list=ls()) # clear environment
wd="C:/Dropboxdata/Dropbox/work/R-statistics/experiments/ssvep_posnalpha_behave/" # work directory
# setwd(wd) # set work directory

# check and install required packages
# Step 1: Get dependencies
deps <- renv::dependencies("FShiftPrime1of2_BRMS_behavior.Rmd")

# Step 2: Extract unique package names
packages_needed <- unique(deps$Package)

# Step 3: Identify which are not yet installed
packages_to_install <- packages_needed[!(packages_needed %in% installed.packages()[, "Package"])]

# Step 4: Install missing packages
if (length(packages_to_install) > 0) {
  install.packages(packages_to_install)
} else {
  message("✅ All required packages are already installed.")
}


# Load relevant libraries:
# library(plyr)
library(psych)
library(ez)
library(ggplot2)
library(lsr)
library(kableExtra)
library(ggbeeswarm)
library(afex)
library(lmerTest)
library(emmeans)
library(lsmeans)
# library(sjPlot)
library(viridis)
library(multcomp)

library(cowplot)
library(readr)

library(ggpol)
library(ggpubr)
library(tidyverse)
library(effectsize)

library(broom)

library(brms)
library(tidybayes)
library(bayesplot)
library(modelr)
library(broom.mixed)
library(magrittr)
library(rstan)
library(posterior)

library(mediation)
library(bayestestR)
library(rstanarm)

library(ggdist)

library(ggtern)

library(DescTools)
library(BayesFactor)

library(dplyr)

# source('C:/Dropboxdata/Dropbox/work/R-statistics/general_functions/RainCloudPlots/tutorial_R/R_rainclouds.R')
# source('C:/Dropboxdata/Dropbox/work/R-statistics/general_functions/RainCloudPlots/tutorial_R/summarySE.R')
# source('C:/Dropboxdata/Dropbox/work/R-statistics/general_functions/RainCloudPlots/tutorial_R/simulateData.R')


source('C:/Dropboxdata/Dropbox/work/R-statistics/examples/Bayesian_rank-based_hypothesis_testing/rankBasedCommonFunctions.R')
source('C:/Dropboxdata/Dropbox/work/R-statistics/examples/Bayesian_rank-based_hypothesis_testing/rankSumSampler.R') # Wilcoxon rank sum function
source('C:/Dropboxdata/Dropbox/work/R-statistics/examples/Bayesian_rank-based_hypothesis_testing/signRankSampler.R') # Wilcoxon signed-rank function
source('C:/Dropboxdata/Dropbox/work/R-statistics/examples/Bayesian_rank-based_hypothesis_testing/spearmanSampler.R')# Spearman's rho function

datafile1 <- "data_in/behavior_events.csv"
datafile2 <- "data_in/behavior_FAs.csv"


```
<style type="text/css">
.main-container {
  max-width: 1800px !important;
  margin-left: auto;
  margin-right: auto;
}
</style>

<br>  

## load single trial data
Loading data `r toString(datafile1)`
Loading data `r toString(datafile2)`

The data has the following structure



```{r load_data,results = "hide", fig.show = "hide", warning = FALSE}
# read in data
DataIn1 <- read_csv(datafile1)
DataIn2 <- read_csv(datafile2)
head(DataIn1)
str(DataIn1)
head(DataIn2)
str(DataIn2)

```


# Motivation

The main idea of the experiment was to test whether the attentional selection of differently colored RDKs depicts different temporal dynamics for *primed* and *purely top-down selected* colors. For this purpose a colored fixation cross was presented that cued participants to attend to one of three RDKs of the color of the fixation cross as well as an additional RDK of another color. The cue-attention assignment had to be learned. Followinf the cue, transient coherent motion events could be presented that had to be indicated by a button press if dots of the cued colors moved coherently.
The here implemented analysis tests the potential differential changes of reaction times across event presentation times for the *primed* and *non-primed* events.

<br>  

```{r RT distribution all trials, results = "hide",  fig.height=3.5, fig.width=5, warning = FALSE, message=FALSE}
dat_plot <- DataIn1 %>%
  filter(response=="hit")


theme_set(theme_bw())
ggplot(dat_plot, aes(x=RT)) +
  stat_dots(position = "dodgejust") +
  labs(
    title = "Reaction times for hits",
    subtitle = "all trials for N = 20 subjects",
    x = "RT in ms",
    y = "density"
  )+ 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```

<br>
Display distribution of RTs


```{r RT, alpha and SSVEP distributions, results = "hide",  fig.height=3.5, fig.width=5, warning = FALSE, message=FALSE}

dat_plot <- DataIn1 %>%
  filter(response=="hit")

mu <- dat_plot %>%
  dplyr::group_by(eventtype2)%>%
  dplyr::summarise(RT = mean(RT,na.rm = TRUE))%>%
  ungroup()%>%
  group_by(eventtype2)%>%
  summarize(grp.mean = mean(RT,na.rm = TRUE), grp.median = median(RT,na.rm = TRUE))


theme_set(theme_bw())
plot1 <-
  ggplot(dat_plot, aes(
    x = RT, 
    fill = eventtype2
  )) +
  stat_slab(
    height = 2, color = "gray15",
    alpha = 0.8,
    expand = TRUE, trim = TRUE,
    fill_type = "segments",
    show.legend = FALSE,
    position = position_dodgejust(0.3),
  )+
  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), axis.title.y = element_blank())+
  theme(axis.text.x=element_blank(),axis.ticks.x=element_blank(), axis.title.x = element_blank())+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  # scale_fill_manual(values=c("#F1831A", "#293C4A", "#198A83")) +
  # scale_color_manual(values=c("#F1831A", "#293C4A", "#198A83"))+
  xlim(c(200, 1300))

plot2 <-
  ggplot(dat_plot, aes(
    x = RT, 
    fill = eventtype2
  )) +
  stat_pointinterval(position = position_dodge(width = .4, preserve = "single"), 
                     aes(color=eventtype2)) +
  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), axis.title.y = element_blank())+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  scale_x_continuous(name="RT in ms", breaks=c(200,400,600,800,1000,1200), labels=waiver(), limits=c(200,1200))
  # scale_fill_manual(name = "cue", values=c("#F1831A", "#293C4A", "#198A83")) +
  # scale_color_manual(name = "cue", values=c("#F1831A", "#293C4A", "#198A83"))
  


# cowplot::plot_grid(plot1, plot2, plot3, ncol = 3,labels = "AUTO")
plotttitle <- ggdraw() + draw_label("RT in ms", fontface='bold')
plotplots <- ggarrange(plot1, plot2, nrow = 2, align = "v", heights =c(4,2), common.legend = TRUE)
ggarrange(plotttitle, plotplots, nrow = 2, heights=c(0.1, 1))

pl.xlim = c(0, 25)


```

<br>

# Analysis Pipeline with brms package
## Intro and Overview

The main research question boils down to: do **Priming** and **presentation time**  have an impact on the reaction times, i.e. do they shift the distribution of reaction times?
Since reaction time distributions differ from the normal distribution (they are for instance not continous and skewed), a mere analysis of the mean may not be the most appropriate procedure. So how can an analysis be implemented?

Some great ideas come from Jonas Kristoffer Lindeløv: https://lindeloev.shinyapps.io/shiny-rt/

A good way to describe RT distribution is to see them as a *log-transformed normal distribution*. It’s called *“log-normal”* because the parameters are the *mean* and *sd* of the log-transformed RTs, which is assumed to be a normal (Gaussian) distribution. These distributions can be modelled with three relevant paremeters:

![image](Lindelov_RT_distributions.png "RT distribution")
<br>
Now what we want to do is check, whether ~~all~~ any of our measures alters parameters of the RT distribution in a systematic and reliable way, i.e. makes reaction times faster or slower for all subjects.

One way of doing this, as also described in the above *shinyapp* is using the `brms` package in R, to model reaction times distributions and their modulations by certain factors. The standard model parameter to be altered by some external factor is **difficulty/mu/$\mu$**.

A potential workflow could be:

1. Fit relevant models wit varying complexity (i.e. intercept model, model incorporating all potential predictors)
2. Compare different models and select the model describing the data best but also most efficiently (i.e. include penalties for the complexity of the model)
3. Extract marginal effects from 'best' model to say something about how and which predictors affect the reaction times

## Implementing the workflow

### Fitting the models
<br>
We are fitting several different models differing in complexity. The brms packages uses some sophisticated sampling procedures to navigate through the parameter space and find the best parameters. For all the parameters priors can (and actually should be applied). This is, however, tricky, as the format of the parameters is not totally clear to me: i.e. for lognormal distributions one should specify the expected size of the effect, the intercept, the shift of the distribution etc. Whether the parameters relate to the actual *RT in ms* or *log(RT in ms)* is not clear to me and may even differ across parameters.

**Footnotes**:

* the NDT parameter for instance seems to relate to *RT in ms* while intercept or effect priors seem to relate to *log(RT in ms)*; again some thoughts here https://discourse.mc-stan.org/t/weakly-informative-priors-for-shifted-lognormal/16206 and here https://lindeloev.shinyapps.io/shiny-rt/#43_priors_and_descriptives

* some handcoded testing/simulations revealed that *no prior* vs *post-hoc a priori priors derived from the parameter space of fitted data* performed comparable, so the standard priors worked in this case; while badly scaled *a prior priors* messed up the fits quite a bit

Usually the modell fitting takes some time as repeatedly fits models for a number of times (by default 4000) and should be run on a dedicated workstation. But specifying a name for the logfile saves the model fit and just re-estimates it in case of any changes.

The models specified so far:

*models*

* intercept model: **RT ~ 1 + ( 1 | subjects)**
* PrimeCon model: **RT ~ PrimeCon + ( PrimeCon | subjects)**
* Presentation Time model: **RT ~ PresTime + ( 1 | subjects)**

*full model with and without interaction*

* PrimeCon + Presentation model: **RT ~ PrimeCon + PresTime + ( PrimeCon | subjects)**
* PrimeCon *+* Presentation model: **RT ~ PrimeCon *+* PresTime + ( PrimeCon | subjects)**
* PrimeCon *+* Presentation model: **RT ~ PrimeCon *+* PresTime + ( PrimeCon | subjects)** [with smoothed gam]


```{r model fits, results = "hide",  fig.height=3.5, fig.width=5, warning = FALSE, message=FALSE}
modeldata = DataIn1 %>%
  filter(response=="hit")

# intercept model
fit_intercept = brm(formula = RT ~ 1 + (1|participant),
          data = modeldata, 
          family = shifted_lognormal(),
          file = 'fit_intercept_slog',
          save_pars = save_pars(all = TRUE),
          file_refit = "on_change",
          # file_refit = "always",
          # file_refit = "never",
          cores = 8
          )  # Save all that hard work.

# PrimeCon model
fit_PrimeCon = brm(formula = RT ~ eventtype2 + (eventtype2|participant),
          data = modeldata, 
          family = shifted_lognormal(),
          file = 'fit_PrimeCon_slog',
          save_pars = save_pars(all = TRUE),
          file_refit = "on_change",
          # file_refit = "always",
          # file_refit = "never",
          cores = 8
          )  # Save all that hard work.


# PrensentationTime model
fit_PresTime = brm(formula = RT ~ eventonsettimes + (1|participant),
          data = modeldata, 
          family = shifted_lognormal(),
          file = 'fit_PresTime_slog',
          save_pars = save_pars(all = TRUE),
          file_refit = "on_change",
          # file_refit = "always",
          # file_refit = "never",
          cores = 8
          )  # Save all that hard work.


# PrimeCon+PrensentationTime model
fit_PrimeCon_PresTime = brm(formula = RT ~ eventtype2 + eventonsettimes + (eventtype2|participant),
          data = modeldata, 
          family = shifted_lognormal(),
          file = 'fit_PrimeCon_PresTime_slog',
          save_pars = save_pars(all = TRUE),
          file_refit = "on_change",
          # file_refit = "always",
          # file_refit = "never",
          cores = 8
          )  # Save all that hard work.

# PrimeCon*PrensentationTime model
fit_PrimeCon_x_PresTime = brm(formula = RT ~ eventtype2 * eventonsettimes + (eventtype2|participant),
          data = modeldata, 
          family = shifted_lognormal(),
          file = 'fit_PrimeCon_x_PresTime_slog',
          save_pars = save_pars(all = TRUE),
          file_refit = "on_change",
          # file_refit = "always",
          # file_refit = "never",
          cores = 8
          )  # Save all that hard work.


# PrimeCon*PrensentationTime model
fit_PrimeCon_x_PresTime_GAM = brm(formula = RT ~ eventtype2 + s(eventonsettimes, by = eventtype2)  + (eventtype2|participant),
          data = modeldata, 
          family = shifted_lognormal(),
          file = 'fit_PrimeCon_x_PresTime_GAM_slog',
          save_pars = save_pars(all = TRUE),
          file_refit = "on_change",
          # file_refit = "always",
          # file_refit = "never",
          cores = 8
          )  # Save all that hard work.

# some testing
 # marginal_smooths(fit_PrimeCon_x_PresTime_GAM)

```

### Comparing models
In order to compare models we need to add some parameters of information critera to the model fits. They are a mysterious measure of the goodness of the model takiing into account the log-likelihood matrix of the fits and the complexity of the model. They are hard to interprete by themselves but allow comparing between models. Some related questions can be found here: https://avehtari.github.io/modelselection/CV-FAQ.html#1_What_is_cross-validation

There is a [glossary](https://mc-stan.org/loo/reference/loo-glossary.html), that briefly explains the different parameters such as **elpd** (expected log pointwise density) which is an estimate of the expected predictive accuracy and is based on somehow sampling the already existing draws/simulations. Statistical magic...

#### adding information criteria for all model estimates
this also takes some time as it is based on a cross validation procedure; but once run it is saved with the previously defined log file.

``` {r add model ICs, fig.height=6, fig.width=10, warning=FALSE, eval = TRUE}
## check for convergence
summary(fit_intercept)
summary(fit_PrimeCon)
summary(fit_PresTime)
summary(fit_PrimeCon_PresTime)
summary(fit_PrimeCon_x_PresTime)
summary(fit_PrimeCon_x_PresTime_GAM)

# adding information criteria
fit_intercept <- add_criterion(fit_intercept, c("loo", "waic", "bayes_R2"))
fit_PrimeCon <- add_criterion(fit_PrimeCon, c("loo", "waic", "bayes_R2"))

fit_PresTime <- add_criterion(fit_PresTime, c("loo", "waic", "bayes_R2"))
fit_PrimeCon_PresTime <- add_criterion(fit_PrimeCon_PresTime, c("loo", "waic", "bayes_R2"))
fit_PrimeCon_x_PresTime <- add_criterion(fit_PrimeCon_x_PresTime, c("loo", "waic", "bayes_R2"))
fit_PrimeCon_x_PresTime_GAM<- add_criterion(fit_PrimeCon_x_PresTime_GAM, c("loo", "waic", "bayes_R2"))

```

#### actual comparisons between models

The central question is: which is the best model for our data. By asking *Which model best explains our data?* we also more explicitely formalize the mechanism we expect to be implemented and somehow put them to test.

The function `loo_compare` allows to compare different models and orders the input models according to their ELPD model. Best in first row and ordered by their difference. There are some rules of thumb, ([see here](https://avehtari.github.io/modelselection/CV-FAQ.html#12_What_is_the_interpretation_of_ELPD__elpd_loo__elpd_diff)):

1. elpd_diff values below 4 are weak
2. If elpd difference is larger than 4, then compare that difference to standard error of elpd_diff

One approach would be to check all the *RT* models separately first and compare these models with the intercept-only as well as vilidity models. And finally compare all to more complex models.

In addition we can compute a Byesian version of the R² value for brms regression models for all the models.

```{r model comparisons, fig.height=6, fig.width=10, warning=FALSE, eval = TRUE}
# alpha contra target
loo_compare(fit_intercept, fit_PrimeCon, fit_PresTime, fit_PrimeCon_PresTime, fit_PrimeCon_x_PresTime, fit_PrimeCon_x_PresTime_GAM,
            criterion = c("loo"))%>%
  kable(escape = F, digits = c(9,9,9,9,9,9,9,9,9), caption = c("RT models | loo comparison")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))



as.data.frame(rbind(
  bayes_R2(fit_intercept), bayes_R2(fit_PrimeCon), bayes_R2(fit_PresTime),
  bayes_R2(fit_PrimeCon_PresTime), bayes_R2(fit_PrimeCon_x_PresTime), bayes_R2(fit_PrimeCon_x_PresTime_GAM)),
  row.names = c("fit_intercept","fit_PrimeCon", "fit_PresTime",
                "fit_PrimeCon_PresTime","fit_PrimeCon_x_PresTime","fit_PrimeCon_x_PresTime_GAM"))%>%
  kable(escape = F, digits = c(9,9,9,9,9,9,9,9,9), caption = c("RT models | bayes_R2")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))



# extract model weights
# via stacking: Each model in a set is fitted to the training data: a subset of p * N observations in data. From these models a prediction is produced on the remaining part of data (the test or hold-out data). These hold-out predictions are fitted to the hold-out observations, by optimising the weights by which the models are combined. This process is repeated R times, yielding a distribution of weights for each model (which Smyth & Wolpert (1998) referred to as an ‘empirical Bayesian estimate of posterior model probability’). A mean or median of model weights for each model is taken and re-scaled to sum to one.
# or via loo epld score
data.frame(model_weight = model_weights(fit_intercept, fit_PrimeCon,
                            fit_PresTime, fit_PrimeCon_PresTime, fit_PrimeCon_x_PresTime,fit_PrimeCon_x_PresTime_GAM,
                            weights = "loo")) %>%
  kable(escape = F, digits = c(9,9,9,9,9,9,9,9,9), caption = c("RT models | model weights via model_weights(...)")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))

# # via loo_model_weights (takes long!)
# data.frame(model_weight = brms::loo_model_weights(fit_intercept, fit_validity,
#                             fit_validity_visalpha, fit_validity_x_visalpha,
#                             fit_validity_alpha2, fit_validity_x_alpha2,
#                             fit_validity_alpha1_alpha2, fit_validity_x_alpha1_alpha2,
#                             fit_validity_SSVEP, fit_validity_x_SSVEP,
#                             fit_validity_SSVEP_alpha, fit_validity_x_SSVEP_alpha)) %>%
#   kable(escape = F, digits = c(6,6,6,6,6,6,6,6,6), 
#         caption = c("alpha, ssvep and combined models | model weights via loo_model_weights(...)")) %>%
#   kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))
  


# ## useful functions to evaluate best model
# # extract summary of model
# summary(fit_validity_visalpha)
# # extract all fitted parameters with summary
# tidy(fit_validity_visalpha)
# # see all coefficients
# coef(fit_validity_visalpha)
# # plot distributions of parameters and evaluation across single draws (catarpillar plot: should look like a noisy eeg channel)
# plot(fit_validity_visalpha, ask = FALSE)
# # plot effects
# plot(conditional_effects(fit_validity_visalpha), ask = FALSE)
# # plot fitted response times and random draws
# pp_check(fit_validity_visalpha, ndraws=100, prefix = c("ppc"))
# # plot some information criteria (basedon on loo, leave-one-out resampling)
# print(loo(fit_validity_visalpha))


```

How to interprete the findings now?

The most complex model seems to be winning! **`fit_PrimeCon_x_PresTime`** with the formula **'RT ~ Cue +  visual_alpha_Targ + ( cue | subjects)'**

This means that in our data, the RT in each trial is best modelled by considering

* interindividual differences
* the presentation time of the event INTERACTING WITH
* whether the event was prime-cued or non-prime cued **primed** vs **nonprimed**

We can now describe the marginal effects for the best model. 

###  Extract marginal effects from non-GAM model

The procedure is nicely described here https://www.andrewheiss.com/blog/2021/11/10/ame-bayes-re-guide/

We first display the effects of the model...but they are hard to interprete as they are probably on a log scale. But who knows.

```{r PrimeCon_x_PresTime marginal effects disp effects,  fig.height=3.5, fig.width=5,  warning = FALSE, message=FALSE, eval = TRUE}
# based on https://www.andrewheiss.com/blog/2021/11/10/ame-bayes-re-guide/
# which model to use?
bestmodel.ef.model <- fit_PrimeCon_x_PresTime
# bestmodel.ef.model <- fit_PrimeCon_x_PresTime_GAM
# what is the data of the model?
bestmodel.ef.data <- bestmodel.ef.model$data

# marginal_smooths(fit_PrimeCon_x_PresTime_GAM)
# posterior_smooths(fit_PrimeCon_x_PresTime_GAM)

# see data
#head(bestmodel.ef.data)

# show effects of the model
tidy(bestmodel.ef.model)%>%
  kable(escape = F, digits = c(6,6,6,6,6,6,6,6,6), caption = c("effects of best model")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))
```

#### Create new data and add predicted RTs

We then create a new data set with an eventonset times amplitude value fixed at the median of the original data, to be able to illustrate the distribution of the marginal means and their effect for the attentional cue, i.e. the factor **PRIMEING**

Based on the new data we can extract **predicted values** or **expected predicted values**. The former also includes the  uncertainty for each individual observation (e.g., observational-level residual variance) of each prediction. We're however more interested in the latter, which more focusses on the uncertainty in the model parameters and not necessarily the individual-level residuals.

```{r PrimeCon_x_PresTime marginal effects disp effects PRIME -data,  fig.height=3.5, fig.width=5,  warning = FALSE, message=FALSE, eval = TRUE}
# use range of data from orignal study 
bestmodel.ef.newdata1 <- expand_grid(
  eventtype2 = c('target_primed','target_nonprimed'),
  eventonsettimes  = median(bestmodel.ef.data$eventonsettimes ),
  # subject = as.factor(unique(bestmodel.ef.data$subject))
  subject = as.factor(c(120, 119, 118)) # for a 'new' subject
)

# use 'predicted_draws' to draw from posterior predictive distribution
# this still incorporates variance of each individual observation in the model
# we may not want to have this around for marginal effects, awe we're more focused on the expected value
bestmodel.ef.tidy_pred <- bestmodel.ef.model %>%
  predicted_draws(newdata = bestmodel.ef.newdata1, allow_new_levels = TRUE)
head(bestmodel.ef.tidy_pred)%>%
  kable(escape = F, digits = c(6,6,6,6,6,6,6,6,6), caption = c("predicted data")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))



# use 'expected draws' ('epred_draws') as we're more intereste in the expected value of the outcome
# which means we’re more focused on the uncertainty in the model parameters and not necessarily the individual-level residuals
# same as fitte function (only with nicer wrapper)
bestmodel.ef.tidy_exppred <- bestmodel.ef.model %>%
  epred_draws(newdata = bestmodel.ef.newdata1, allow_new_levels = TRUE)
head(bestmodel.ef.tidy_exppred)%>%
  kable(escape = F, digits = c(6,6,6,6,6,6,6,6,6), caption = c("predicted data")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))
  
pl.xlim = c(500, 1000)


# different plot
theme_set(theme_bw())
plot1 <-
  ggplot(bestmodel.ef.tidy_exppred, aes(
    x = .epred, 
    fill = eventtype2, fill_ramp = after_stat(abs(x)), 
    color_ramp = after_stat(-dnorm(x, 0, 2))
  )) +
  stat_slab(
    height = 2, color = "gray15",
    expand = TRUE, trim = TRUE,
    fill_type = "segments",
    show.legend = FALSE,
    position = position_dodgejust(0.3),
  )+
  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), axis.title.y = element_blank())+
  theme(axis.text.x=element_blank(),axis.ticks.x=element_blank(), axis.title.x = element_blank())+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  scale_fill_manual(values=c("red3","steelblue")) +
  scale_color_manual(values=c("red3", "steelblue"))+
  # scale_fill_manual(name="cue", values=c("#F1831A", "#293C4A", "#198A83")) +
  # scale_color_manual(name="cue",values=c("#F1831A", "#293C4A", "#198A83"))+
  xlim(pl.xlim)

plot2 <-
  ggplot(bestmodel.ef.tidy_exppred, aes(
    x = .epred, 
    fill = eventtype2
  )) +
  stat_pointinterval(position = position_dodge(width = .4, preserve = "single"), 
                     aes(color=eventtype2)) +
  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), axis.title.y = element_blank())+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  scale_x_continuous(name="RT in ms", breaks=waiver(), labels=waiver(), limits=pl.xlim)+
  scale_fill_manual(values=c("red3","steelblue")) +
  scale_color_manual(values=c("red3", "steelblue"))
  # scale_fill_manual(name="cue", values=c("#F1831A", "#293C4A", "#198A83")) +
  # scale_color_manual(name="cue", values=c("#F1831A", "#293C4A", "#198A83"))

# cowplot::plot_grid(plot1, plot2, plot3, ncol = 3,labels = "AUTO")
plotttitle <- ggdraw() + draw_label("predicted RT in ms | for all model draws", fontface='bold')
plotplots <- ggarrange(plot1, plot2, nrow = 2, align = "v", heights =c(4,2), common.legend = TRUE)
ggarrange(plotttitle, plotplots, nrow = 2, heights=c(0.1, 1))
```

#### Predicted RTs for factor ATTENTIONPRIME

Now with the `emmeans` package, we can extract the distribution of median RTs derived from the predicted RT-value distributions of each single draw/simulation. We can also directly calculate contrasts and derive the 95%-CI of the effects.

```{r PrimeCon_x_PresTime marginal effects disp effects PRIME -marginal means,  fig.height=3.5, fig.width=5,  warning = FALSE, message=FALSE, eval = TRUE}

# now we want to see the effects using emmeans
# check cue validity effect via pairwise comparisons
# first the emmeans (point estimate = median of distrbution)
bestmodel.ef.model %>% 
  emmeans(~ eventtype2,
          epred = TRUE)%>%
  kable(escape = F, digits = c(3,3,3,6,3,3,3,3,3), 
        caption = c("average marginal effect | point measure = median of RT in ms")) %>%
  # kable_classic(full_width = F) %>%
  column_spec(1, bold = T)%>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))

# pairwise comparisons
bestmodel.ef.model %>% 
  emmeans(~ eventtype2,
          epred = TRUE)%>% 
  contrast(method = "revpairwise")%>%
  kable(escape = F, digits = c(3,3,3,6,3,3,3,3,3), 
        caption = c("average marginal effect differences | point measure = median of RT in ms")) %>%
  # kable_classic(full_width = F) %>%
  column_spec(1, bold = T)%>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))

# now gather all the single draws to be able to plot the variance predicted RTs for different validity levels
bestmodel.ef.ef_draws_PRIME <- bestmodel.ef.model %>% 
  emmeans(~ eventtype2,
          epred = TRUE)%>% 
  gather_emmeans_draws()

theme_set(theme_bw())
g <- ggplot(bestmodel.ef.ef_draws_PRIME, aes(y = eventtype2, x = .value)) +
  stat_halfeye(
    aes(fill = eventtype2, fill_ramp = after_stat(level)),
    .width = c(.95, 1),
    position = "dodgejust",
  ) +
  scale_fill_manual(values=c("red3","steelblue")) +
  scale_color_manual(values=c("red3", "steelblue"))+
  # scale_fill_manual(values=c("#F1831A", "#293C4A", "#198A83")) +
  # scale_color_manual(values=c("#F1831A", "#293C4A", "#198A83"))+
  labs(
    title = "Average predicted RTs in ms", 
    subtitle = "based on medians for all draws of the model",
    fill_ramp = "interval",
    x = "predicted RT in ms",
    y = "validity"
  )

print(g)
# ggsave(filename = "figures/MarginEffects_Validity_PredRTs_ModelValVisAlpha.eps", width = 5, height = 3.5,
#        plot = print(g))


# now gather all the single draws to be able to plot the variance of the contrast
bestmodel.ef.ef_draws_PRIME_contr <- bestmodel.ef.model %>% 
  emmeans(~ eventtype2,
          epred = TRUE)%>% 
  contrast(method = "revpairwise") %>%
  gather_emmeans_draws()

theme_set(theme_bw())
g<-ggplot(bestmodel.ef.ef_draws_PRIME_contr, aes( x = .value)) +
  stat_halfeye(
    aes(fill = contrast, fill_ramp = after_stat(level)),
    .width = c(.95, 1),
    position = "dodgejust",
  ) +
  geom_vline(xintercept = 0)+
  # scale_fill_brewer(palette = "Reds")+
  labs(
    title = "Average marginal effect in ms", 
    subtitle = "based on medians for all draws of the model",
    fill_ramp = "interval",
    x = "predicted difference in ms",
    y = "density"
  )

print(g)
# ggsave(filename = "figures/MarginEffects_Validity_Contrasts_ModelValVisAlpha.eps", width = 5, height = 3.5,
#        plot = print(g))


# savefig %<>%
#   fill_panel(saveplot, column = 1, row = 1)
# savefig
# save_multi_panel_figure(savefig, "figures/FFT_BeeSwarm_Mod_ColXPos_INTER_POSXCOL_AllExpPooled.eps")
```

#### Effects of time point of target presentation

We now can similarly extract the slopes of the **eventonsettime** and **RT** relationship

```{r PrimeCon_x_PresTime marginal effects disp effects visual alpha -marginal means,  fig.height=3.5, fig.width=5,  warning = FALSE, message=FALSE, eval = TRUE}
## alpha contra target
# use range of data from orignal study with varying alpha contra target (in range of original data)
bestmodel.ef.newdata2 <- expand_grid(
  eventtype2 = c('target_primed','target_nonprimed'),
  eventonsettimes = seq(min(bestmodel.ef.data$eventonsettimes),max(bestmodel.ef.data$eventonsettimes),0.05),
  subject = as.factor(c(120, 119, 118)) # for a 'new' subject
)


# use 'expected draws' ('epred_draws') as we're more intereste in the expected value of the outcome
# which means we’re more focused on the uncertainty in the model parameters and not necessarily the individual-level residuals
# same as fitte function (only with nicer wrapper)
bestmodel.ef.tidy_exppred2 <- bestmodel.ef.model %>%
  epred_draws(newdata = bestmodel.ef.newdata2, allow_new_levels = TRUE)
head(bestmodel.ef.tidy_exppred2)%>%
  kable(escape = F, digits = c(6,6,6,6,6,6,6,6,6), caption = c("predicted data")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))
  
theme_set(theme_bw())
ggplot(bestmodel.ef.tidy_exppred2, aes(x = eventonsettimes, y = .epred, fill=eventtype2)) +
  stat_lineribbon(.width = c(0.95, 1),aes(fill_ramp = after_stat(level))) + 
  # scale_fill_brewer(palette = "Purples") +
  scale_fill_manual(values=c("red3","steelblue")) +
  # scale_color_manual(values=c("red3", "steelblue"))+
  facet_grid(.~eventtype2)+
  labs(x = "event onset times", y = "predicted RT",
       fill = "Credible interval",
       title = "Marginal Means", 
       subtitle = "for all draws of the model",) +
  # ylim(c(400,1300))+
  theme(legend.position = "bottom")


# now lets get the slop of the modulation by alpha
bestmodel.ef.slope_interaction <- bestmodel.ef.model %>% 
  emtrends(~ eventtype2, # 1 means, we want the average slop
           var = "eventonsettimes",
           epred = TRUE) %>% 
  gather_emmeans_draws()


theme_set(theme_bw())
g<-ggplot(bestmodel.ef.slope_interaction, aes( x = .value, y=eventtype2)) +
  stat_halfeye(
    aes(fill = eventtype2, fill_ramp = after_stat(level)),
    .width = c(.95, 1),
  ) +
  # stat_dots(aes(fill = alpha_signal,color = alpha_signal, fill_ramp = after_stat(level), colour_ramp = after_stat(level)),
  #           .width = c(.95, 1))+
  geom_vline(xintercept = 0)+
  # facet_grid(cue_validity_label~.)+
  scale_fill_manual(values=c("red3","steelblue")) +
  scale_color_manual(values=c("red3", "steelblue"))+
  labs(
    title = "Slopes: event onset times", 
    subtitle = "for all draws of the model",
    fill_ramp = "interval",
    colour_ramp = "interval",
    x = "slope"
  )


print(g)
# ggsave(filename = "figures/MarginEffects_PostCue_FullModelVisAlpha_Alpha_SlopeDistr.eps",
#        width = 4, height = 4,
#        plot = print(g))


bestmodel.ef.slope_interaction %>% median_hdi() %>%
  kable(escape = F, digits = c(3,3,3,3,3,3,6,6,6), caption = c("slopes for eventtimes RT relationship: mean and CI")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))

# contrast across draws
# now lets get the slop of the modulation by alpha
bestmodel.ef.slope_interaction <- bestmodel.ef.model %>% 
  emtrends(~ eventtype2, # 1 means, we want the average slop
           var = "eventonsettimes",
           epred = TRUE) %>% 
  contrast(method = "revpairwise") %>%
  gather_emmeans_draws()

theme_set(theme_bw())
g<-ggplot(bestmodel.ef.slope_interaction, aes( x = .value)) +
  stat_halfeye(
    aes(fill = contrast, fill_ramp = after_stat(level)),
    .width = c(.95, 1),
    position = "dodgejust",
  ) +
  geom_vline(xintercept = 0)+
  # scale_fill_brewer(palette = "Reds")+
  labs(
    title = "Contrast | marginal effect in ms", 
    subtitle = "based on medians for all draws of the model",
    fill_ramp = "interval",
    x = "predicted difference in ms",
    y = "density"
  )

print(g)


bestmodel.ef.slope_interaction %>% median_hdi() %>%
  kbl(escape = F, digits = c(3,3,3,3,3,3,6,6,6), caption = c("contrast of slopes for eventtimes RT relationship: mean and CI")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))

```

###  Extract marginal effects from GAM model

The procedure is nicely described here https://www.andrewheiss.com/blog/2021/11/10/ame-bayes-re-guide/

We first display the effects of the model...but they are hard to interprete as they are probably on a log scale. But who knows.

```{r PrimeCon_x_PresTime_GAM marginal effects disp effects,  fig.height=3.5, fig.width=5,  warning = FALSE, message=FALSE, eval = TRUE}
# based on https://www.andrewheiss.com/blog/2021/11/10/ame-bayes-re-guide/
# which model to use?
# bestmodel.ef.model <- fit_PrimeCon_x_PresTime
bestmodel.ef.model <- fit_PrimeCon_x_PresTime_GAM
# what is the data of the model?
bestmodel.ef.data <- bestmodel.ef.model$data

marginal_smooths(fit_PrimeCon_x_PresTime_GAM,prob = 0.95,)
# conditional_smooths(fit_PrimeCon_x_PresTime_GAM)
# posterior_smooths(fit_PrimeCon_x_PresTime_GAM)

# see data
#head(bestmodel.ef.data)

# show effects of the model
tidy(bestmodel.ef.model)%>%
  kable(escape = F, digits = c(6,6,6,6,6,6,6,6,6), caption = c("effects of best model")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))
```

#### Create new data and add predicted RTs

We then create a new data set with an eventonset times amplitude value fixed at the median of the original data, to be able to illustrate the distribution of the marginal means and their effect for the attentional cue, i.e. the factor **PRIMEING**

Based on the new data we can extract **predicted values** or **expected predicted values**. The former also includes the  uncertainty for each individual observation (e.g., observational-level residual variance) of each prediction. We're however more interested in the latter, which more focusses on the uncertainty in the model parameters and not necessarily the individual-level residuals.

```{r PrimeCon_x_PresTime_GAM marginal effects disp effects PRIME -data,  fig.height=3.5, fig.width=5,  warning = FALSE, message=FALSE, eval = TRUE}
# use range of data from orignal study 
bestmodel.ef.newdata1 <- expand_grid(
  eventtype2 = c('target_primed','target_nonprimed'),
  eventonsettimes  = median(bestmodel.ef.data$eventonsettimes ),
  # subject = as.factor(unique(bestmodel.ef.data$subject))
  subject = as.factor(c(120, 119, 118)) # for a 'new' subject
)

# use 'predicted_draws' to draw from posterior predictive distribution
# this still incorporates variance of each individual observation in the model
# we may not want to have this around for marginal effects, awe we're more focused on the expected value
bestmodel.ef.tidy_pred <- bestmodel.ef.model %>%
  predicted_draws(newdata = bestmodel.ef.newdata1, allow_new_levels = TRUE)
head(bestmodel.ef.tidy_pred)%>%
  kable(escape = F, digits = c(6,6,6,6,6,6,6,6,6), caption = c("predicted data")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))

# user posterior smooth (?)
bestmodel.ef.tidy_pred_smooth <- bestmodel.ef.model %>%
  brms::posterior_smooths(smooth="s(eventonsettimes, by = eventtype2)",newdata = bestmodel.ef.newdata1,allow_new_levels = TRUE)


  


# use 'expected draws' ('epred_draws') as we're more intereste in the expected value of the outcome
# which means we’re more focused on the uncertainty in the model parameters and not necessarily the individual-level residuals
# same as fitte function (only with nicer wrapper)
bestmodel.ef.tidy_exppred <- bestmodel.ef.model %>%
  epred_draws(newdata = bestmodel.ef.newdata1, allow_new_levels = TRUE)
head(bestmodel.ef.tidy_exppred)%>%
  kable(escape = F, digits = c(6,6,6,6,6,6,6,6,6), caption = c("predicted data")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))
  
pl.xlim = c(500, 1000)


# different plot
theme_set(theme_bw())
plot1 <-
  ggplot(bestmodel.ef.tidy_exppred, aes(
    x = .epred, 
    fill = eventtype2, fill_ramp = after_stat(abs(x)), 
    color_ramp = after_stat(-dnorm(x, 0, 2))
  )) +
  stat_slab(
    height = 2, color = "gray15",
    expand = TRUE, trim = TRUE,
    fill_type = "segments",
    show.legend = FALSE,
    position = position_dodgejust(0.3),
  )+
  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), axis.title.y = element_blank())+
  theme(axis.text.x=element_blank(),axis.ticks.x=element_blank(), axis.title.x = element_blank())+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  scale_fill_manual(values=c("red3","steelblue")) +
  scale_color_manual(values=c("red3", "steelblue"))+
  # scale_fill_manual(name="cue", values=c("#F1831A", "#293C4A", "#198A83")) +
  # scale_color_manual(name="cue",values=c("#F1831A", "#293C4A", "#198A83"))+
  xlim(pl.xlim)

plot2 <-
  ggplot(bestmodel.ef.tidy_exppred, aes(
    x = .epred, 
    fill = eventtype2
  )) +
  stat_pointinterval(position = position_dodge(width = .4, preserve = "single"), 
                     aes(color=eventtype2)) +
  theme(axis.text.y=element_blank(),axis.ticks.y=element_blank(), axis.title.y = element_blank())+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  scale_x_continuous(name="RT in ms", breaks=waiver(), labels=waiver(), limits=pl.xlim)+
  scale_fill_manual(values=c("red3","steelblue")) +
  scale_color_manual(values=c("red3", "steelblue"))
  # scale_fill_manual(name="cue", values=c("#F1831A", "#293C4A", "#198A83")) +
  # scale_color_manual(name="cue", values=c("#F1831A", "#293C4A", "#198A83"))

# cowplot::plot_grid(plot1, plot2, plot3, ncol = 3,labels = "AUTO")
plotttitle <- ggdraw() + draw_label("predicted RT in ms | for all model draws", fontface='bold')
plotplots <- ggarrange(plot1, plot2, nrow = 2, align = "v", heights =c(4,2), common.legend = TRUE)
ggarrange(plotttitle, plotplots, nrow = 2, heights=c(0.1, 1))




```

#### Predicted RTs for factor ATTENTIONPRIME

Now with the `emmeans` package, we can extract the distribution of median RTs derived from the predicted RT-value distributions of each single draw/simulation. We can also directly calculate contrasts and derive the 95%-CI of the effects.

```{r PrimeCon_x_PresTime_GAM marginal effects disp effects PRIME -marginal means,  fig.height=3.5, fig.width=5,  warning = FALSE, message=FALSE, eval = TRUE}

# now we want to see the effects using emmeans
# check cue validity effect via pairwise comparisons
# first the emmeans (point estimate = median of distrbution)
bestmodel.ef.model %>% 
  emmeans(~ eventtype2,
          epred = TRUE)%>%
  kable(escape = F, digits = c(3,3,3,6,3,3,3,3,3), 
        caption = c("average marginal effect | point measure = median of RT in ms")) %>%
  # kable_classic(full_width = F) %>%
  column_spec(1, bold = T)%>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))

# pairwise comparisons
bestmodel.ef.model %>% 
  emmeans(~ eventtype2,
          epred = TRUE)%>% 
  contrast(method = "revpairwise")%>%
  kable(escape = F, digits = c(3,3,3,6,3,3,3,3,3), 
        caption = c("average marginal effect differences | point measure = median of RT in ms")) %>%
  # kable_classic(full_width = F) %>%
  column_spec(1, bold = T)%>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))

# now gather all the single draws to be able to plot the variance predicted RTs for different validity levels
bestmodel.ef.ef_draws_PRIME <- bestmodel.ef.model %>% 
  emmeans(~ eventtype2,
          epred = TRUE)%>% 
  gather_emmeans_draws()

theme_set(theme_bw())
g <- ggplot(bestmodel.ef.ef_draws_PRIME, aes(y = eventtype2, x = .value)) +
  stat_halfeye(
    aes(fill = eventtype2, fill_ramp = after_stat(level)),
    .width = c(.95, 1),
    position = "dodgejust",
  ) +
  scale_fill_manual(values=c("red3","steelblue")) +
  scale_color_manual(values=c("red3", "steelblue"))+
  # scale_fill_manual(values=c("#F1831A", "#293C4A", "#198A83")) +
  # scale_color_manual(values=c("#F1831A", "#293C4A", "#198A83"))+
  labs(
    title = "Average predicted RTs in ms", 
    subtitle = "based on medians for all draws of the model",
    fill_ramp = "interval",
    x = "predicted RT in ms",
    y = "validity"
  )

print(g)
# ggsave(filename = "figures/MarginEffects_Validity_PredRTs_ModelValVisAlpha.eps", width = 5, height = 3.5,
#        plot = print(g))


# now gather all the single draws to be able to plot the variance of the contrast
bestmodel.ef.ef_draws_PRIME_contr <- bestmodel.ef.model %>% 
  emmeans(~ eventtype2,
          epred = TRUE)%>% 
  contrast(method = "revpairwise") %>%
  gather_emmeans_draws()

theme_set(theme_bw())
g<-ggplot(bestmodel.ef.ef_draws_PRIME_contr, aes( x = .value)) +
  stat_halfeye(
    aes(fill = contrast, fill_ramp = after_stat(level)),
    .width = c(.95, 1),
    position = "dodgejust",
  ) +
  geom_vline(xintercept = 0)+
  # scale_fill_brewer(palette = "Reds")+
  labs(
    title = "Average marginal effect in ms", 
    subtitle = "based on medians for all draws of the model",
    fill_ramp = "interval",
    x = "predicted difference in ms",
    y = "density"
  )

print(g)
# ggsave(filename = "figures/MarginEffects_Validity_Contrasts_ModelValVisAlpha.eps", width = 5, height = 3.5,
#        plot = print(g))


# savefig %<>%
#   fill_panel(saveplot, column = 1, row = 1)
# savefig
# save_multi_panel_figure(savefig, "figures/FFT_BeeSwarm_Mod_ColXPos_INTER_POSXCOL_AllExpPooled.eps")
```

#### Effects of time point of target presentation

We now can similarly extract the slopes of the **eventonsettime** and **RT** relationship

```{r PrimeCon_x_PresTime_GAM marginal effects disp effects visual alpha -marginal means,  fig.height=3.5, fig.width=5,  warning = FALSE, message=FALSE, eval = TRUE}
## alpha contra target
# use range of data from orignal study with varying alpha contra target (in range of original data)
bestmodel.ef.newdata2 <- expand_grid(
  eventtype2 = c('target_primed','target_nonprimed'),
  eventonsettimes = seq(min(bestmodel.ef.data$eventonsettimes),max(bestmodel.ef.data$eventonsettimes),0.02),
  subject = as.factor(c(120, 119, 118)) # for a 'new' subject
)


# use 'expected draws' ('epred_draws') as we're more intereste in the expected value of the outcome
# which means we’re more focused on the uncertainty in the model parameters and not necessarily the individual-level residuals
# same as fitte function (only with nicer wrapper)
bestmodel.ef.tidy_exppred2 <- bestmodel.ef.model %>%
  epred_draws(newdata = bestmodel.ef.newdata2, allow_new_levels = TRUE)
head(bestmodel.ef.tidy_exppred2)%>%
  kable(escape = F, digits = c(6,6,6,6,6,6,6,6,6), caption = c("predicted data")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))
  
theme_set(theme_bw())
ggplot(bestmodel.ef.tidy_exppred2, aes(x = eventonsettimes, y = .epred, fill=eventtype2)) +
  stat_lineribbon(.width = c(0.95, 1),aes(fill_ramp = after_stat(level))) + 
  # scale_fill_brewer(palette = "Purples") +
  scale_fill_manual(values=c("red3","steelblue")) +
  # scale_color_manual(values=c("red3", "steelblue"))+
  facet_grid(.~eventtype2)+
  labs(x = "event onset times", y = "predicted RT",
       fill = "Credible interval",
       title = "Marginal Means", 
       subtitle = "for all draws of the model",) +
  # ylim(c(400,1300))+
  theme(legend.position = "bottom")


# now lets get the slop of the modulation by alpha
bestmodel.ef.slope_interaction <- bestmodel.ef.model %>% 
  emtrends(~ eventtype2, # 1 means, we want the average slop
           var = "eventonsettimes",
           epred = TRUE) %>% 
  gather_emmeans_draws()


theme_set(theme_bw())
g<-ggplot(bestmodel.ef.slope_interaction, aes( x = .value, y=eventtype2)) +
  stat_halfeye(
    aes(fill = eventtype2, fill_ramp = after_stat(level)),
    .width = c(.95, 1),
  ) +
  # stat_dots(aes(fill = alpha_signal,color = alpha_signal, fill_ramp = after_stat(level), colour_ramp = after_stat(level)),
  #           .width = c(.95, 1))+
  geom_vline(xintercept = 0)+
  # facet_grid(cue_validity_label~.)+
  scale_fill_manual(values=c("red3","steelblue")) +
  scale_color_manual(values=c("red3", "steelblue"))+
  labs(
    title = "Slopes: event onset times", 
    subtitle = "for all draws of the model",
    fill_ramp = "interval",
    colour_ramp = "interval",
    x = "slope"
  )


print(g)
# ggsave(filename = "figures/MarginEffects_PostCue_FullModelVisAlpha_Alpha_SlopeDistr.eps",
#        width = 4, height = 4,
#        plot = print(g))


bestmodel.ef.slope_interaction %>% median_hdi() %>%
  kable(escape = F, digits = c(3,3,3,3,3,3,6,6,6), caption = c("slopes for eventtimes RT relationship: mean and CI")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))

# contrast across draws
# now lets get the slop of the modulation by alpha
bestmodel.ef.slope_interaction <- bestmodel.ef.model %>% 
  emtrends(~ eventtype2, # 1 means, we want the average slop
           var = "eventonsettimes",
           epred = TRUE) %>% 
  contrast(method = "revpairwise") %>%
  gather_emmeans_draws()

theme_set(theme_bw())
g<-ggplot(bestmodel.ef.slope_interaction, aes( x = .value)) +
  stat_halfeye(
    aes(fill = contrast, fill_ramp = after_stat(level)),
    .width = c(.95, 1),
    position = "dodgejust",
  ) +
  geom_vline(xintercept = 0)+
  # scale_fill_brewer(palette = "Reds")+
  labs(
    title = "Contrast | marginal effect in ms", 
    subtitle = "based on medians for all draws of the model",
    fill_ramp = "interval",
    x = "predicted difference in ms",
    y = "density"
  )

print(g)

bestmodel.ef.slope_interaction %>% median_hdi() %>%
  kbl(escape = F, digits = c(3,3,3,3,3,3,6,6,6), caption = c("contrast of slopes for eventtimes RT relationship: mean and CI")) %>%
  kable_styling("striped", full_width = T, bootstrap_options = c("striped", "hover", "condensed", "responsive",font_size = 8))


```



